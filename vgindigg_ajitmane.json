{
	"jobConfig": {
		"name": "vgindigg_ajitmane",
		"description": "",
		"role": "arn:aws:iam::258115715286:role/service-role/AWSGlueServiceRole-vgdataiamrolefinal",
		"command": "glueetl",
		"version": "3.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "vgindigg_ajitmane.py",
		"scriptLocation": "s3://aws-glue-assets-258115715286-ap-south-1/scripts/",
		"language": "python-3",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2023-06-23T05:05:14.971Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-258115715286-ap-south-1/temporary/",
		"logging": true,
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"spark": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-258115715286-ap-south-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"sourceControlDetails": {
			"Provider": "GITHUB",
			"Folder": "vgindigg_ajitmane"
		}
	},
	"hasBeenSaved": false,
	"script": "# Video Game Sales And Steam Video Games - Dataset Exploration and Cleaning\n\n# Installing pyspark and findspark library\n!pip install pyspark\n!pip install findspark\n\n# Importing necessary libraries\nimport pyspark\nimport findspark\nfindspark.init()\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import col, sum\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.context import GlueContext\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\n\n# Creating instance of spark\nspark = SparkSession.builder.appName(\"Data Exploration and Cleaning\").getOrCreate()\nspark\n\n\n# Create a GlueContext\nsc = SparkContext()\nglueContext = GlueContext(sc)\n\n# Create a DynamicFrame from the \"vgsales\" dataset in S3\nvgsales_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    format=\"csv\",\n    format_options={\"withHeader\": True},\n    connection_options={\"paths\": [\"s3://vgindiggdatafinal/inputfolder/vgsales.csv\"]}\n)\n\n# Create a DynamicFrame from the \"vgtraffic\" dataset in S3\nvgtraffic_df = glueContext.create_dynamic_frame.from_options(\n    connection_type=\"s3\",\n    format=\"csv\",\n    format_options={\"withHeader\": True},\n    connection_options={\"paths\": [\"s3://vgindiggdatafinal/inputfolder/steam-200k.csv\"]}\n)\n\n# Video games sales dataset\nvgsales_df.show()\n\n# Video games traffic dataset\nvgtraffic_df.show()\n\n# Adding column names for video games traffic dataset\ncolumn_name=[ 'user-id', 'game-title', 'behavior-name', 'value','0']\nvgtraffic_df = vgtraffic_df.toDF(*column_name)\nvgtraffic_df.show()\n\n# Data Inispection\n\n# Checking number of rows and columns present in each dataset\n\n# Check the number of rows and columns for vgsales_df\nprint(f\"vgsales_df contains {vgsales_df.count()} rows and {len(vgsales_df.columns)} columns\")\n\n# Check the number of rows and columns for vgtraffic_df\nprint(f\"vgtraffic_df contains {vgtraffic_df.count()} rows and {len(vgtraffic_df.columns)} columns\")\n\n# Checking schema of the datasets\nvgsales_df.printSchema()\nvgtraffic_df.printSchema()\n\n# Understanding Variables\n\n# Checking categorical and numerical variables from each dataset\n\n# Categorical and numerical variables in the \"Video Game sales\" dataset\nvgsales_categorical_cols = []\nvgsales_numerical_cols = []\n\nfor column, dtype in vgsales_df.dtypes:\n    if dtype == \"string\":\n        vgsales_categorical_cols.append(column)\n    elif dtype in [\"int\",\"double\"]:\n        vgsales_numerical_cols.append(column)\n\nprint(f\"{len(vgsales_categorical_cols)} categorical columns present in 'Video Game sales' dataset: {vgsales_categorical_cols}\")\nprint(f\"{len(vgsales_numerical_cols)} Numerical columns present in 'Video Game sales' dataset: {vgsales_numerical_cols}\")\n\n\n# Categorical and numerical variables in the \"Video Games traffic on steam\" dataset\nvgtraffic_categorical_cols = []\nvgtraffic_numerical_cols = []\n\nfor column, dtype in vgtraffic_df.dtypes:\n    if dtype == \"string\":\n        vgtraffic_categorical_cols.append(column)\n    elif dtype in [\"byte\", \"short\", \"int\", \"long\", \"float\", \"double\"]:\n        vgtraffic_numerical_cols.append(column)\n\nprint(f\"{len(vgtraffic_categorical_cols)} categorical columns present in 'Video Games traffic data' dataset: {vgtraffic_categorical_cols}\")\nprint(f\"{len(vgtraffic_numerical_cols)} numerical columns present in 'Video Games traffic data' dataset: {vgtraffic_numerical_cols}\")\n\n## Data Cleaning and Preprocessing\n\n#[1] Handling Duplicated data\n\n# Check for duplicates in the \"Video Game sales\" dataset\nvgsales_duplicates = vgsales_df.dropDuplicates()\nnum_vgsales_duplicates = vgsales_duplicates.count()\n\nif num_vgsales_duplicates > 0:\n    print(\"Duplicates found in 'Video Game sales' dataset.\")\n    print(\"Number of duplicate rows:\", num_vgsales_duplicates)\nelse:\n    print(\"No duplicates found in 'Video Game sales' dataset.\")\n\n# Check for duplicates in the \"Video Games traffic on steam\" dataset\nvgtraffic_duplicates = vgtraffic_df.dropDuplicates()\nnum_vgtraffic_duplicates = vgtraffic_duplicates.count()\n\nif num_vgtraffic_duplicates > 0:\n    print(\"Duplicates found in 'Video Games traffic on steam' dataset.\")\n    print(\"Number of duplicate rows:\", num_vgtraffic_duplicates)\nelse:\n    print(\"No duplicates found in 'Video Games traffic on steam' dataset.\")\n\n\n# Dropping duplicated\n\n# Drop duplicates in the \"Video Game sales\" dataset\nvgsales_duplicates_removed = vgsales_df.dropDuplicates()\nnum_vgsales_rows = vgsales_duplicates_removed.count()\n\nprint(\"Number of rows remaining after dropping duplicates in 'Video Game sales' dataset:\", num_vgsales_rows)\n\n# Drop duplicates in the \"Video Games traffic on steam\" dataset\nvgtraffic_duplicates_removed = vgtraffic_df.dropDuplicates()\nnum_vgtraffic_rows = vgtraffic_duplicates_removed.count()\n\nprint(\"Number of rows remaining after dropping duplicates in 'Video Games traffic' dataset:\", num_vgtraffic_rows)\n\n# [2] Handling null/missing data\n\n# Checking null values for each dataset\n\nfrom pyspark.sql.functions import col, sum\n\n# Calculate the number of nulls for each variable in the \"Video Game sales\" dataset\nvgsales_null_counts = vgsales_duplicates_removed.select(*[sum(col(c).isNull().cast(\"int\")).alias(c) for c in vgsales_duplicates_removed.columns])\n\n# Calculate the number of nulls for each variable in the \"Video Games traffic on steam\" dataset\nvgtraffic_null_counts = vgtraffic_duplicates_removed.select(*[sum(col(c).isNull().cast(\"int\")).alias(c) for c in vgtraffic_duplicates_removed.columns])\n\n# Create a table to display the variable name and number of nulls for the \"Video Game sales\" dataset\nvgsales_null_table = spark.createDataFrame([(c, vgsales_null_counts.first()[c]) for c in vgsales_null_counts.columns], [\"Variable\", \"Nulls\"])\n\n# Create a table to display the variable name and number of nulls for the \"Video Games traffic on steam\" dataset\nvgtraffic_null_table = spark.createDataFrame([(c, vgtraffic_null_counts.first()[c]) for c in vgtraffic_null_counts.columns], [\"Variable\", \"Nulls\"])\n\n# Show the null table for the \"Video Game sales\" dataset\nprint(\"Null values in 'Video Game sales' dataset:\")\nvgsales_null_table.show(truncate=False)\n\n# Show the null table for the \"Video Games traffic on steam\" dataset\nprint(\"Null values in 'Video Games traffic on steam' dataset:\")\nvgtraffic_null_table.show(truncate=False)\n\n# [3] Basic description of both dataset\n\n# Display the schema information of the \"Video Games traffic on steam\" dataset\nprint(\"Schema information of 'Video Games traffic on steam' dataset:\")\nvgtraffic_duplicates_removed.printSchema()\n\n# Display the schema information of the \"Video Game sales\" dataset\nprint(\"Schema information of 'Video Game sales' dataset:\")\nvgsales_duplicates_removed.printSchema()\n\n# Remove the \"0\" column from the traffic dataset\nvgtraffic_duplicates_removed = vgtraffic_duplicates_removed.drop(\"0\")\n\n# Convert the \"Year\" column in the sales dataset from string to integer\nvgsales_duplicates_removed = vgsales_duplicates_removed.withColumn(\"Year\", vgsales_duplicates_removed[\"Year\"].cast(\"integer\"))\n\n# Print the schema of the modified \"Video Games traffic\" dataset\nprint(\"Schema of 'Video Games traffic on steam' dataset after removing the '0' column:\")\nvgtraffic_duplicates_removed.printSchema()\n\n# Print the schema of the modified \"Video Game sales\" dataset\nprint(\"Schema of 'Video Game sales' dataset after converting the 'Year' column to integer:\")\nvgsales_duplicates_removed.printSchema()\n\n\n# [4] Merge datasets\n\n# DataFrames vgsales_duplicates_removed and vgtraffic_duplicates_removed\n\n# Merge the datasets based on common columns\nmerged_df = vgsales_duplicates_removed.join(\n    vgtraffic_duplicates_removed,\n    vgsales_duplicates_removed[\"Name\"] == vgtraffic_duplicates_removed[\"game-title\"],\n    \"inner\"\n)\n\n# Show the merged DataFrame\nmerged_df.show()\n\n# [5] Checking correlation between Viewers and Global_Sales\n\n# Optionally, perform additional analysis or computations on the merged data\ncorrelation = merged_df.select(\"Global_Sales\", \"value\").corr(\"Global_Sales\", \"value\")\n\n# Output the merged data and correlation result\nmerged_df.show(10)\nprint(\"Correlation between Global Sales and Viewers:\", correlation)\n"
}